{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0268c0bf79256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "local_model_ckpt = \"/root/hugging_model_hub/distilbert-base-uncased\"\n",
    "local_dataset = \"/root/hugging_model_hub/datasets/emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_ckpt)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(local_model_ckpt).to(device)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "def extract_hidden_state(batch):\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}\n",
    "\n",
    "emotion_datasets = load_dataset(local_dataset)\n",
    "emotions_encoded = emotion_datasets.map(tokenize, batched=True, batch_size=None)\n",
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "emotions_hidden = emotions_encoded.map(extract_hidden_state, batched=True)\n",
    "print(emotions_hidden['train'].column_names, emotions_hidden['train'].shape)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
    "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
    "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
    "\n",
    "# from umap import UMAP\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # Scale features to [0,1] range\n",
    "# X_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "# # Initialize and fit UMAP\n",
    "# mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "# # Create a DataFrame of 2D embeddings\n",
    "# df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
    "# df_emb[\"label\"] = y_train\n",
    "# print(df_emb.head())\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(7, 5))\n",
    "# axes = axes.flatten()\n",
    "# cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
    "labels = emotion_datasets[\"train\"].features[\"label\"].names\n",
    "# for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "#     df_emb_sub = df_emb.query(f\"label == {i}\")\n",
    "#     axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap,\n",
    "#                    gridsize=20, linewidths=(0,))\n",
    "#     axes[i].set_title(label)\n",
    "#     axes[i].set_xticks([]), axes[i].set_yticks([])\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#simple classifer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr_clf = LogisticRegression(max_iter=3000)\n",
    "# lr_clf.fit(X_train, y_train)\n",
    "# lr_score=lr_clf.score(X_valid, y_valid)\n",
    "# print('lr_score:', lr_score)\n",
    "\n",
    "# #dummy classifer\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "# dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# dummy_clf.fit(X_train, y_train)\n",
    "# dummy_score=dummy_clf.score(X_valid, y_valid)\n",
    "# print('dummy_score:', dummy_score)\n",
    "\n",
    "#investigate performance of model by confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    matrix=confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    figure, axies = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=axies, colorbar=False)\n",
    "    plt.title(\"Normalize confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# y_preds=lr_clf.predict(X_valid)\n",
    "# plot_confusion_matrix(y_preds, y_valid, labels)\n",
    "\n",
    "# fine-tune with transformers\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "num_labels=6\n",
    "model=AutoModelForSequenceClassification.from_pretrained(local_model_ckpt, num_labels=num_labels).to(device)\n",
    "\n",
    "#define model performance metrics using in trainning\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments, Trainer\n",
    "\n",
    "def compute_metrics(pred):\n",
    "     labels = pred.label_ids\n",
    "     preds = pred.predictions.argmax(-1)\n",
    "     f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "     acc = accuracy_score(labels, preds)\n",
    "     return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "#define hyper parameters\n",
    "batch_size=64\n",
    "logging_steps=len(emotions_encoded[\"train\"]) // batch_size\n",
    "model_name=f\"{local_model_ckpt}-finetune-emotion\"\n",
    "train_args=TrainingArguments(output_dir=model_name,\n",
    "                              num_train_epochs=2,\n",
    "                              learning_rate=2e-5,\n",
    "                              per_device_train_batch_size=batch_size,\n",
    "                              per_device_eval_batch_size=batch_size,\n",
    "                              weight_decay=0.01,\n",
    "                              eval_strategy=\"epoch\",\n",
    "                              disable_tqdm=False,\n",
    "                              logging_steps=logging_steps,\n",
    "                              push_to_hub=False,\n",
    "                              log_level=\"error\"\n",
    ")\n",
    "trainer = Trainer(model=model, args=train_args, compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded[\"train\"],\n",
    "                  eval_dataset=emotions_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()\n",
    "\n",
    "# validate performance\n",
    "preds_output = trainer.predict(emotions_encoded[\"validation\"])\n",
    "preds_output.metrics\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
