{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a6352d92625e73",
   "metadata": {},
   "source": [
    "# BitNet \n",
    "\n",
    "论文地址：https://arxiv.org/pdf/2504.12285\n",
    "\n",
    "## 模型配置\n",
    "\n",
    "参数量：~2 Billion  \n",
    "训练token：4 Trillion  \n",
    "上下文最大长度：4096 tokens\n",
    "Tokenizer： LLaMA 3 Tokenizer (vocab size: 128,256)\n",
    "\n",
    "## Architecture: Transformer-based, modified with BitLinear layers (BitNet framework)\n",
    "* 采用 Rotary Position Embeddings (RoPE)   <br/><br/> \n",
    "\n",
    "    用于 Transformer 模型的位置编码方法，相对于传统的位置编码（如 sin/cos、可学习位置向量等）来说的一种新颖方式。<br/>\n",
    "    传统的位置编码方法，是 将位置信息直接加或拼接到 token 的 embedding 上；而 RoPE 是将位置编码内置在 attention 中，<br/>\n",
    "    通过旋转方式引入位置信息：<br/> 对 Query 和 Key 做一个基于位置的旋转变换，使得 Attention Score 中自然体现位置信息的差异。<br/><br/>\n",
    "\n",
    "    **特性**：相对位置感知；无限长度扩展性（与 LLaMA 一起用于 extrapolation 到更长输入）；纯函数实现，无需学习参数；更适合多语言、大模型（已用于多个 SOTA 模型）  \n",
    "\n",
    "    RoFormer: Enhanced Transformer with Rotary Position Embedding (论文地址：https://arxiv.org/abs/2104.09864) <br/><br/> \n",
    "\n",
    "* squared ReLU (ReLU²) activation in FFN layers (squared ReLU (ReLU²) <br/><br/> \n",
    "    是一种在 Transformer 中替代普通 ReLU 激活函数的变体，常用于 FFN 层（前馈 <br/>\n",
    "神经网络 FeedForward Layer） 中。其基本思想是将 ReLU 的输出再平方一次，从而产生更稀疏、更集中的激活分布。)  <br/><br/> \n",
    "    \n",
    "    **特性**:  <br/>\n",
    "    更稀疏的激活(小于 1 的数平方变得更小，趋向于 0);  \n",
    "    有助于表示能力(加强激活差异，提升模型表示力);  \n",
    "    \n",
    "* 采用 subln（Sub-Layer Normalization） 归一化：一种在 Transformer 的 子层（sub-layer）内使用的 LayerNorm 方式。  \n",
    "\n",
    "* 线性层或者归一化层不适用偏置项  \n",
    "\n",
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "id": "acb1e6143d6a2a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:10:35.501443Z",
     "start_time": "2025-04-21T12:09:46.143516Z"
    }
   },
   "source": [
    "!pip install git+https://github.com/shumingma/transformers.git"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting git+https://github.com/shumingma/transformers.git\r\n",
      "  Cloning https://github.com/shumingma/transformers.git to /private/var/folders/_0/f08g_6v53fx_19c_xz7kcsnr0000gn/T/pip-req-build-nzipj877\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/shumingma/transformers.git /private/var/folders/_0/f08g_6v53fx_19c_xz7kcsnr0000gn/T/pip-req-build-nzipj877\r\n",
      "  Resolved https://github.com/shumingma/transformers.git to commit eb28a5caa9853d45266b1ea6548e8fb2cf2fb855\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (2.2.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.52.0.dev0) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from requests->transformers==4.52.0.dev0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from requests->transformers==4.52.0.dev0) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11413960 sha256=5eb274d425cc2486173d5eaf8d7ab05f16e801000e88095d7fdef43a69739c2b\r\n",
      "  Stored in directory: /private/var/folders/_0/f08g_6v53fx_19c_xz7kcsnr0000gn/T/pip-ephem-wheel-cache-ad01isw9/wheels/89/35/bb/fc7e028ddbbdfa31d65bcf55ed0f86a723597c0eccfa46e6c8\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.51.3\r\n",
      "    Uninstalling transformers-4.51.3:\r\n",
      "      Successfully uninstalled transformers-4.51.3\r\n",
      "Successfully installed transformers-4.52.0.dev0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "865f8c63aac985e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:30:04.666338Z",
     "start_time": "2025-04-21T12:28:32.020361Z"
    }
   },
   "source": [
    "# !pip uninstall torch -y\n",
    "# !pip install torch==2.2.1 --force-reinstall\n",
    "# !pip show transformers\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==2.2.2  --index-url https://download.pytorch.org/whl/cpu"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\r\n",
      "Collecting torch==2.2.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2-cp310-none-macosx_10_9_x86_64.whl (151.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.0/151.0 MB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:03\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.2.2) (2025.3.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from jinja2->torch==2.2.2) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages (from sympy->torch==2.2.2) (1.3.0)\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-2.2.2\r\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "9181c9d84b8baf1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:33:08.135444Z",
     "start_time": "2025-04-21T12:32:35.125412Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"microsoft/bitnet-b1.58-2B-4T\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.__file__)\n",
    "print(hasattr(torch, \"get_default_device\"))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(message, tokenize=False, add_special_tokens=True)\n",
    "chat_input = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "chat_outputs = model.generate(**chat_input, max_new_tokens=50)\n",
    "response = tokenizer.decode(chat_outputs[0][chat_input['input_ids'].shape[-1]:])\n",
    "print(\"\\nAssistant Response:\", response)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_0/f08g_6v53fx_19c_xz7kcsnr0000gn/T/ipykernel_94143/1670926030.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "/Users/admin/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\n",
      "False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'get_default_device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mhasattr\u001B[39m(torch, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_default_device\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     10\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id)\n\u001B[0;32m---> 11\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbfloat16\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m message \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     14\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are a helpful AI assistant.\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     15\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow are you?\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     16\u001B[0m ]\n\u001B[1;32m     18\u001B[0m prompt \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mapply_chat_template(message, tokenize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, add_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:571\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mconfig_class \u001B[38;5;241m==\u001B[39m config\u001B[38;5;241m.\u001B[39msub_configs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_config\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    570\u001B[0m         config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget_text_config()\n\u001B[0;32m--> 571\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    577\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:282\u001B[0m, in \u001B[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    280\u001B[0m old_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mget_default_dtype()\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    284\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_default_dtype(old_dtype)\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:4171\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   4169\u001B[0m \u001B[38;5;66;03m# Potentially detect context manager or global device, and use it (only if no device_map was provided)\u001B[39;00m\n\u001B[1;32m   4170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_deepspeed_zero3_enabled():\n\u001B[0;32m-> 4171\u001B[0m     device_in_context \u001B[38;5;241m=\u001B[39m \u001B[43mget_torch_context_manager_or_global_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4172\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device_in_context \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeta\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   4173\u001B[0m         \u001B[38;5;66;03m# TODO Cyril: raise an error instead of the warning in v4.53 (and change the test to check for raise instead of success)\u001B[39;00m\n\u001B[1;32m   4174\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m   4175\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe detected that you are using `from_pretrained` with a meta device context manager or `torch.set_default_device(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmeta\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4176\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is an anti-pattern and will raise an Error in version v4.53\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf you want to initialize a model on the meta device, use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4177\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe context manager or global device with `from_config`, or `ModelClass(config)`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4178\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:295\u001B[0m, in \u001B[0;36mget_torch_context_manager_or_global_device\u001B[0;34m()\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03mTest if a device context manager is currently in use, or if it is not the case, check if the default device\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03mis not \"cpu\". This is used to infer the correct device to load the model on, in case `device_map` is not provided.\u001B[39;00m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    294\u001B[0m device_in_context \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([])\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m--> 295\u001B[0m default_device \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_default_device\u001B[49m()\n\u001B[1;32m    296\u001B[0m \u001B[38;5;66;03m# This case means no context manager was used -> we still check if the default that was potentially set is not cpu\u001B[39;00m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device_in_context \u001B[38;5;241m==\u001B[39m default_device:\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py:1938\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m   1935\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m   1936\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m-> 1938\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute 'get_default_device'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
